{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASO PRÁCTICO 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Se solicita refactorizar el siguiente código para validar accesos de un usuario*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined object repository\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "object repository {\n",
    "  def getUser(userNme: String): String = userNme.split(\"@\")(0)\n",
    "\n",
    "  def login(usr: String, pwd: String): Boolean = {\n",
    "      var a = false\n",
    "      if (usr == \"awainer\") {\n",
    "          if (pwd == \"123\") {\n",
    "              a = true\n",
    "          }\n",
    "      }\n",
    "      return a\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<console>:34: warning: a pure expression does nothing in statement position; you may be omitting necessary parentheses\n",
       "               return true\n",
       "                      ^\n",
       "<console>:34: warning: enclosing method shouldBechecking_login has result type Unit: return value discarded\n",
       "               return true\n",
       "               ^\n",
       "<console>:51: warning: a pure expression does nothing in statement position; you may be omitting necessary parentheses\n",
       "             return false\n",
       "                    ^\n",
       "<console>:51: warning: enclosing method shouldBechecking_login has result type Unit: return value discarded\n",
       "             return false\n",
       "             ^\n",
       "shouldBechecking_login: (userNme: String, pwd: String)Unit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "def shouldBechecking_login(userNme: String, pwd: String) {\n",
    "    val usr = repository.getUser(userNme)\n",
    "    var msg = \"\"\n",
    "    var result = false\n",
    "    if (usr != null) {\n",
    "      if (repository.login(usr, pwd)) {\n",
    "        println(\"Válido\")\n",
    "        return true\n",
    "\n",
    "      }\n",
    "      else {\n",
    "        msg = \"Invalid user or password\"\n",
    "        result = false\n",
    "\n",
    "      }\n",
    "\n",
    "    }\n",
    "    else {\n",
    "      msg = \"Invalid user\"\n",
    "      result = false\n",
    "\n",
    "    }\n",
    "    if (msg != null) {\n",
    "      println(msg)\n",
    "      return false\n",
    "\n",
    "    }\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid user or password\n"
     ]
    }
   ],
   "source": [
    "shouldBechecking_login(\"awainer@demo.com\", \"1234\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid user or password\n"
     ]
    }
   ],
   "source": [
    "shouldBechecking_login(\"\", \"123\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASO PRÁCTICO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Se solicita refactorizar el siguiente código para generar estadísticas de trazabilidad de un dataFrame*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marco_de_datos = [campaign_start_date: date, personal_type: string ... 4 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[campaign_start_date: date, personal_type: string ... 4 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val marco_de_datos = spark.read.parquet(\"processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfStats: (marco_de_datos: org.apache.spark.sql.DataFrame, PRM_SPARK_STATS_LEVEL: Int, spark_partition_id: String)Unit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.util.SizeEstimator\n",
    "import org.apache.spark.sql.functions.desc\n",
    "\n",
    "def dfStats(marco_de_datos:DataFrame, PRM_SPARK_STATS_LEVEL:Int, spark_partition_id:String):Unit = {\n",
    "\n",
    "  val dfPartitionNum = marco_de_datos.rdd.getNumPartitions\n",
    "    \n",
    "  if (PRM_SPARK_STATS_LEVEL>0) {\n",
    "    val dfSizeByte: BigInt = marco_de_datos.queryExecution.optimizedPlan.stats.sizeInBytes\n",
    "    val dfSizeMb: Float = dfSizeByte.toFloat / 1024.toFloat / 1024.toFloat\n",
    "    val dfSizeEstimatorMb: Float = SizeEstimator.estimate(marco_de_datos).toFloat / 1024.toFloat / 1024.toFloat\n",
    "\n",
    "   println(\"*** STATS *** Df Stats PlanSizeMB:\"+dfSizeMb+\",  EstimatorSizeMB:\"+dfSizeEstimatorMb+\", PartitionNum: \"+dfPartitionNum\n",
    "           +\", PartitionSizeMB:\"+dfSizeMb / dfPartitionNum+\", PartitionSizeMB:\"+dfSizeEstimatorMb / dfPartitionNum)\n",
    "  }\n",
    "    \n",
    "  if (PRM_SPARK_STATS_LEVEL==2 || PRM_SPARK_STATS_LEVEL==4) {\n",
    "   println(s\"*** STATS *** Df Partitioon record count ${marco_de_datos.count()}\")\n",
    "  }\n",
    "    \n",
    "  // check the partitions data\n",
    "  if (PRM_SPARK_STATS_LEVEL==3 || PRM_SPARK_STATS_LEVEL==4) {\n",
    "    println(s\"*** STATS *** Df Partitioon Info\")\n",
    "    marco_de_datos\n",
    "      .groupBy(spark_partition_id)\n",
    "      .count()\n",
    "      .orderBy(desc(\"count\"))\n",
    "      .show(if (dfPartitionNum>0) dfPartitionNum else 200)\n",
    "  }\n",
    "    \n",
    "  if (PRM_SPARK_STATS_LEVEL==8) {\n",
    "    println(s\"*** STATS *** Show data:\")\n",
    "    marco_de_datos.show()\n",
    "  }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** STATS *** Df Stats PlanSizeMB:9.864668,  EstimatorSizeMB:138.33743, PartitionNum: 4, PartitionSizeMB:2.466167, PartitionSizeMB:34.58436\n"
     ]
    }
   ],
   "source": [
    "dfStats(marco_de_datos, 1, \"cutoff_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** STATS *** Df Stats PlanSizeMB:9.864668,  EstimatorSizeMB:138.45236, PartitionNum: 4, PartitionSizeMB:2.466167, PartitionSizeMB:34.61309\n",
      "*** STATS *** Df Partitioon record count 1282382\n"
     ]
    }
   ],
   "source": [
    "dfStats(marco_de_datos, 2, \"cutoff_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** STATS *** Df Stats PlanSizeMB:9.864668,  EstimatorSizeMB:138.88104, PartitionNum: 4, PartitionSizeMB:2.466167, PartitionSizeMB:34.72026\n",
      "*** STATS *** Df Partitioon Info\n",
      "+-----------+-------+\n",
      "|cutoff_date|  count|\n",
      "+-----------+-------+\n",
      "| 2020-01-03|1282382|\n",
      "+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfStats(marco_de_datos, 3, \"cutoff_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** STATS *** Df Stats PlanSizeMB:9.864668,  EstimatorSizeMB:139.5444, PartitionNum: 4, PartitionSizeMB:2.466167, PartitionSizeMB:34.8861\n",
      "*** STATS *** Show data:\n",
      "+-------------------+-------------+-----------+------------------+--------------------+-----------+\n",
      "|campaign_start_date|personal_type|personal_id|      segment_desc|   audtiminsert_date|cutoff_date|\n",
      "+-------------------+-------------+-----------+------------------+--------------------+-----------+\n",
      "|         2019-09-30|            L|   00081633|  08. Bajo ingreso|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   00950462|  08. Bajo ingreso|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   02446085|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   06674137|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   06694902|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   07247000|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   07699179|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   08464270|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   16769553|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   17804824|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   20709077|11. IND - NO SUNAT|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   21564496|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   25809138|11. IND - NO SUNAT|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   29204932|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   29416368|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   40150611|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   40169609|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   41051997|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   41630769|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   43192411|11. IND - NO SUNAT|2019-11-07 19:12:...| 2020-01-03|\n",
      "+-------------------+-------------+-----------+------------------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfStats(marco_de_datos, 8, \"cutoff_date\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
