{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "desirable-riverside",
   "metadata": {},
   "source": [
    "#### Ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "great-ferry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.1.33:4041\n",
       "SparkContext available as 'sc' (version = 3.1.1, master = local[*], app id = local-1617079210812)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.DataFrame\n",
       "import org.apache.spark.util.SizeEstimator\n",
       "import org.apache.spark.sql.functions.desc\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.DataFrame;\n",
    "import org.apache.spark.util.SizeEstimator;\n",
    "import org.apache.spark.sql.functions.desc;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "neither-gnome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataScheme: org.apache.spark.sql.DataFrame = [campaign_start_date: date, personal_type: string ... 4 more fields]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val DataScheme: DataFrame = spark.read.parquet(\"processed\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adult-saver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class EvaluateDataFrame\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EvaluateDataFrame (val dataScheme: DataFrame,\n",
    "                         val prmSparkStatsLevel: Int,\n",
    "                         val sparkPartitionId: String) {\n",
    "    val partitions = dataScheme.rdd.getNumPartitions\n",
    "    require(prmSparkStatsLevel > 0, \"\"\"Spark level must be\n",
    "    greater than 0\"\"\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "political-portugal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class DataframeSize\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DataframeSize(val df: DataFrame) {\n",
    "    def toBytes(): BigInt = {\n",
    "        df.queryExecution.optimizedPlan.stats.sizeInBytes\n",
    "    }\n",
    "    def toMb(size: Float): Float = {\n",
    "        size.toFloat / 1024.toFloat / 1024.toFloat\n",
    "    }\n",
    "    def toEstimatorMb(): Float = {\n",
    "        toMb(SizeEstimator.estimate(df))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "professional-associate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined trait PrmLevel1\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trait PrmLevel1 {\n",
    "    def dfStats(df: EvaluateDataFrame) = {\n",
    "        val dfSize = new DataframeSize(df.dataScheme: DataFrame)\n",
    "        \n",
    "        val sizeBytes: BigInt = dfSize.toBytes()\n",
    "        val sizeMb: Float = dfSize.toMb(sizeBytes.toFloat)\n",
    "        val sizeEstimatorMb: Float = dfSize.toEstimatorMb()\n",
    "        \n",
    "        println(\"*** STATS *** Df Stats PlanSizeMB:\"+sizeMb+\n",
    "                \",  EstimatorSizeMB:\"+sizeEstimatorMb+\n",
    "                \", PartitionNum: \"+df.partitions+\n",
    "                \", PartitionSizeMB:\"+sizeMb / df.partitions+\n",
    "                \", PartitionSizeMB:\"+sizeEstimatorMb / df.partitions)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "prime-morrison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined trait PrmLevel2\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trait PrmLevel2 extends PrmLevel1 {\n",
    "    override def dfStats(df: EvaluateDataFrame) = {\n",
    "        super.dfStats(df);\n",
    "        println(s\"\"\"*** STATS *** Df Partition record \n",
    "               count ${df.dataScheme.count()}\"\"\");\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "listed-equality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined trait PrmLevel3\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trait PrmLevel3 extends PrmLevel1 {\n",
    "    override def dfStats(df: EvaluateDataFrame) = {\n",
    "        super.dfStats(df);\n",
    "        println(s\"*** STATS *** Df Partition Info\");\n",
    "        df.dataScheme\n",
    "          .groupBy(df.sparkPartitionId)\n",
    "          .count()\n",
    "          .orderBy(desc(\"count\"))\n",
    "          .show(if (df.partitions>0) df.partitions else 200);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "several-logic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined trait PrmLevel8\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trait PrmLevel8 extends PrmLevel1 {\n",
    "    override def dfStats(df: EvaluateDataFrame) = {\n",
    "        super.dfStats(df);\n",
    "        println(s\"*** STATS *** Show data:\")\n",
    "        df.dataScheme.show() \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "returning-blanket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class PrmSparkStatsLevel1\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PrmSparkStatsLevel1 (val df: EvaluateDataFrame) extends PrmLevel1 {\n",
    "    super.dfStats(df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "opening-steps",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class PrmSparkStatsLevel2\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PrmSparkStatsLevel2 (val df: EvaluateDataFrame) extends PrmLevel2 {\n",
    "    super.dfStats(df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "prime-clock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class PrmSparkStatsLevel3\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PrmSparkStatsLevel3 (val df: EvaluateDataFrame) extends PrmLevel3 {\n",
    "    super.dfStats(df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "thrown-trial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class PrmSparkStatsLevel4\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PrmSparkStatsLevel4 (val df: EvaluateDataFrame) extends PrmLevel2 with PrmLevel3 {\n",
    "    super.dfStats(df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "handy-genius",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class PrmSparkStatsLevel8\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PrmSparkStatsLevel8 (val df: EvaluateDataFrame) extends PrmLevel8 {\n",
    "    super.dfStats(df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "persistent-defense",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df1: EvaluateDataFrame = EvaluateDataFrame@49275ea2\n",
       "df2: EvaluateDataFrame = EvaluateDataFrame@42edf4f7\n",
       "df3: EvaluateDataFrame = EvaluateDataFrame@3e9a1ed5\n",
       "df4: EvaluateDataFrame = EvaluateDataFrame@7580424f\n",
       "df8: EvaluateDataFrame = EvaluateDataFrame@6a1c013\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df1: EvaluateDataFrame = new EvaluateDataFrame(DataScheme, 1, \"cutoff_date\")\n",
    "val df2: EvaluateDataFrame = new EvaluateDataFrame(DataScheme, 2, \"cutoff_date\")\n",
    "val df3: EvaluateDataFrame = new EvaluateDataFrame(DataScheme, 3, \"cutoff_date\")\n",
    "val df4: EvaluateDataFrame = new EvaluateDataFrame(DataScheme, 4, \"cutoff_date\")\n",
    "val df8: EvaluateDataFrame = new EvaluateDataFrame(DataScheme, 8, \"cutoff_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "chicken-baptist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** STATS *** Df Stats PlanSizeMB:9.864668,  EstimatorSizeMB:5.2294617, PartitionNum: 4, PartitionSizeMB:2.466167, PartitionSizeMB:1.3073654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "prm1: PrmSparkStatsLevel1 = PrmSparkStatsLevel1@532876a7\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val prm1 = new PrmSparkStatsLevel1(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "listed-wellington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** STATS *** Df Stats PlanSizeMB:9.864668,  EstimatorSizeMB:5.233917, PartitionNum: 4, PartitionSizeMB:2.466167, PartitionSizeMB:1.3084793\n",
      "*** STATS *** Df Partition record \n",
      "               count 1282382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "prm2: PrmSparkStatsLevel2 = PrmSparkStatsLevel2@a621d5b\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val prm2 = new PrmSparkStatsLevel2(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "wired-transparency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** STATS *** Df Stats PlanSizeMB:9.864668,  EstimatorSizeMB:5.502426, PartitionNum: 4, PartitionSizeMB:2.466167, PartitionSizeMB:1.3756065\n",
      "*** STATS *** Df Partition Info\n",
      "+-----------+-------+\n",
      "|cutoff_date|  count|\n",
      "+-----------+-------+\n",
      "| 2020-01-03|1282382|\n",
      "+-----------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "prm3: PrmSparkStatsLevel3 = PrmSparkStatsLevel3@5da07f36\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val prm3 = new PrmSparkStatsLevel3(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "imposed-monroe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** STATS *** Df Stats PlanSizeMB:9.864668,  EstimatorSizeMB:14.470245, PartitionNum: 4, PartitionSizeMB:2.466167, PartitionSizeMB:3.6175613\n",
      "*** STATS *** Df Partition record \n",
      "               count 1282382\n",
      "*** STATS *** Df Partition Info\n",
      "+-----------+-------+\n",
      "|cutoff_date|  count|\n",
      "+-----------+-------+\n",
      "| 2020-01-03|1282382|\n",
      "+-----------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "prm4: PrmSparkStatsLevel4 = PrmSparkStatsLevel4@2aca30d3\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val prm4 = new PrmSparkStatsLevel4(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "authentic-edition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** STATS *** Df Stats PlanSizeMB:9.864668,  EstimatorSizeMB:15.233841, PartitionNum: 4, PartitionSizeMB:2.466167, PartitionSizeMB:3.8084602\n",
      "*** STATS *** Show data:\n",
      "+-------------------+-------------+-----------+------------------+--------------------+-----------+\n",
      "|campaign_start_date|personal_type|personal_id|      segment_desc|   audtiminsert_date|cutoff_date|\n",
      "+-------------------+-------------+-----------+------------------+--------------------+-----------+\n",
      "|         2019-09-30|            L|   00081633|  08. Bajo ingreso|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   00950462|  08. Bajo ingreso|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   02446085|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   06674137|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   06694902|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   07247000|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   07699179|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   08464270|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   16769553|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   17804824|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   20709077|11. IND - NO SUNAT|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   21564496|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   25809138|11. IND - NO SUNAT|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   29204932|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   29416368|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   40150611|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   40169609|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   41051997|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   41630769|              None|2019-11-07 19:12:...| 2020-01-03|\n",
      "|         2019-09-30|            L|   43192411|11. IND - NO SUNAT|2019-11-07 19:12:...| 2020-01-03|\n",
      "+-------------------+-------------+-----------+------------------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "prm8: PrmSparkStatsLevel8 = PrmSparkStatsLevel8@3244b440\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val prm8 = new PrmSparkStatsLevel8(df8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-supplier",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
